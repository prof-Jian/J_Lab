{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_params(filePath):\n",
    "    with open(filePath, 'r') as f:\n",
    "        params = json.load(f)\n",
    "    f.close()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_params: {'lr_dict': {'worker': 0.0015, 'manager': 0.0015, 'discriminator': 5e-05}, 'decay_step_size': 200, 'decay_rate': 0.99, 'total_epoch': 800, 'generated_num': 156, 'save_num': 10, 'replace_num': 5, 'pre_dis_epoch_num': 50, 'pre_gen_epoch_num': 80, 'pos_filepath': './data/train_corpus.npy', 'neg_filepath': './data/gen_data.npy', 'eval_filepath': './data/eval_data.npy', 'model_path': './ckpts/', 'seed': 233, 'checkpoint_path': None} \n",
      "\n",
      " leak_gan_params: {'discriminator_params': {'seq_len': 20, 'num_classes': 2, 'vocab_size': 5258, 'dis_emb_dim': 64, 'filter_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20], 'num_filters': [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160], 'start_token': 0, 'goal_out_size': None, 'step_size': 5, 'dropout_prob': 0.8, 'l2_reg_lambda': 0.2}, 'generator_params': {'manager_params': {'batch_size': 64, 'hidden_dim': 32, 'goal_out_size': None}, 'worker_params': {'batch_size': 64, 'vocab_size': 5258, 'embed_dim': 32, 'hidden_dim': 32, 'goal_out_size': None, 'goal_size': 16}, 'step_size': 5}} \n",
      "\n",
      " target_params: {'vocab_size': 5000, 'batch_size': 64, 'embed_dim': 32, 'hidden_dim': 32, 'seq_len': 20, 'start_token': 0} \n",
      "\n",
      " dis_data_params: {'positive_filepath': './data/train_corpus.npy', 'negative_filepath': './data/gen_corpus.npy', 'batch_size': 64, 'shuffle': True, 'num_workers': 4, 'pin_memory': False} \n",
      "\n",
      " real_data_params: {'filepath': './data/train_corpus.npy', 'batch_size': 64, 'shuffle': True, 'num_workers': 4, 'pin_memory': False}\n"
     ]
    }
   ],
   "source": [
    "train_params = get_params(\"./params/train_params.json\")\n",
    "leak_gan_params = get_params(\"./params/leak_gan_params.json\")\n",
    "target_params = get_params(\"./params/target_params.json\")\n",
    "dis_data_params = get_params(\"./params/dis_data_params.json\")\n",
    "real_data_params = get_params(\"./params/real_data_params.json\")\n",
    "print( \"train_params:\" ,train_params,\"\\n\\n\",\n",
    "        \"leak_gan_params:\" ,leak_gan_params,\"\\n\\n\",\n",
    "        \"target_params:\" ,target_params,\"\\n\\n\",\n",
    "        \"dis_data_params:\" ,dis_data_params,\"\\n\\n\",\n",
    "        \"real_data_params:\" ,real_data_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_params: {'lr_dict': {'worker': 0.0015, 'manager': 0.0015, 'discriminator': 5e-05}, 'decay_step_size': 200, 'decay_rate': 0.99, 'total_epoch': 800, 'generated_num': 156, 'save_num': 10, 'replace_num': 5, 'pre_dis_epoch_num': 50, 'pre_gen_epoch_num': 80, 'pos_filepath': './data/train_corpus.npy', 'neg_filepath': './data/gen_data.npy', 'eval_filepath': './data/eval_data.npy', 'model_path': './ckpts/', 'seed': 233, 'checkpoint_path': None} \n",
      "\n",
      " leak_gan_params: {'discriminator_params': {'seq_len': 20, 'num_classes': 2, 'vocab_size': 5258, 'dis_emb_dim': 64, 'filter_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20], 'num_filters': [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160], 'start_token': 0, 'goal_out_size': None, 'step_size': 5, 'dropout_prob': 0.8, 'l2_reg_lambda': 0.2}, 'generator_params': {'manager_params': {'batch_size': 64, 'hidden_dim': 32, 'goal_out_size': None}, 'worker_params': {'batch_size': 64, 'vocab_size': 5258, 'embed_dim': 32, 'hidden_dim': 32, 'goal_out_size': None, 'goal_size': 16}, 'step_size': 5}} \n",
      "\n",
      " target_params: {'vocab_size': 5000, 'batch_size': 64, 'embed_dim': 32, 'hidden_dim': 32, 'seq_len': 20, 'start_token': 0} \n",
      "\n",
      " dis_data_params: {'positive_filepath': './data/train_corpus.npy', 'negative_filepath': './data/gen_corpus.npy', 'batch_size': 64, 'shuffle': True, 'num_workers': 4, 'pin_memory': False} \n",
      "\n",
      " real_data_params: {'filepath': './data/train_corpus.npy', 'batch_size': 64, 'shuffle': True, 'num_workers': 4, 'pin_memory': False}\n"
     ]
    }
   ],
   "source": [
    "train_params = get_params(\"./params/train_params.json\")\n",
    "leak_gan_params = get_params(\"./params/leak_gan_params.json\")\n",
    "target_params = get_params(\"./params/target_params.json\")\n",
    "dis_data_params = get_params(\"./params/dis_data_params.json\")\n",
    "real_data_params = get_params(\"./params/real_data_params.json\")\n",
    "print( \"train_params:\" ,train_params,\"\\n\\n\",\n",
    "        \"leak_gan_params:\" ,leak_gan_params,\"\\n\\n\",\n",
    "        \"target_params:\" ,target_params,\"\\n\\n\",\n",
    "        \"dis_data_params:\" ,dis_data_params,\"\\n\\n\",\n",
    "        \"real_data_params:\" ,real_data_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_filepath = './data/gen_corpus.npy'\n",
    "import numpy as np\n",
    "gen_corpus = np.load(negative_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199680"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_corpus.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 319, 2341,  902,  986,  197, 5170, 2609, 1148, 3956, 4507, 1842,\n",
       "       4939, 1574, 2646, 4273, 4778, 3695, 2925, 2212, 4570], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2036, 4029, 1620, ...,  917,  268,  260],\n",
       "       [ 319, 2341,  902, ..., 2925, 2212, 4570],\n",
       "       [4904,  189,  688, ...,  671,  416,   13],\n",
       "       ...,\n",
       "       [ 717, 3149, 4776, ..., 1957, 4663, 1243],\n",
       "       [5117, 1407, 2671, ..., 2175, 3971, 2533],\n",
       "       [1477, 1585,  942, ..., 2756, 3729,  411]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "seq_len= 20\n",
    "num_classes= 2 \n",
    "vocab_size= 5258 \n",
    "dis_emb_dim= 64 \n",
    "filter_sizes= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "num_filters= [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]\n",
    "start_token= 0\n",
    "goal_out_size= sum(num_filters)\n",
    "step_size= 5\n",
    "dropout_prob= 0.8\n",
    "l2_reg_lambda= 0.2\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, seq_len, num_classes, vocab_size, dis_emb_dim, \n",
    "                    filter_sizes, num_filters, start_token, goal_out_size, step_size, dropout_prob, l2_reg_lambda):\n",
    "      \n",
    "        super(Discriminator, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dis_emb_dim = dis_emb_dim\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.start_token = start_token\n",
    "        self.goal_out_size = goal_out_size\n",
    "        self.step_size = step_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.l2_reg_lambda = l2_reg_lambda\n",
    "        self.num_filters_total = sum(self.num_filters)\n",
    "        \n",
    "        #Building up layers\n",
    "        self.emb = nn.Embedding(self.vocab_size + 1, self.dis_emb_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_f, (f_size, self.dis_emb_dim)) for f_size, num_f in zip(self.filter_sizes, self.num_filters)\n",
    "        ])\n",
    "        self.highway = nn.Linear(self.num_filters_total, self.num_filters_total)\n",
    "        #in_features = out_features = sum of num_festures\n",
    "        self.dropout = nn.Dropout(p = self.dropout_prob)\n",
    "        #Randomly zeroes some of the elements of the input tensor with probability p using Bernouli distribution\n",
    "        #Each channel will be zeroed independently onn every forward call\n",
    "        self.fc = nn.Linear(self.num_filters_total, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "            x: shape(batch_size * self.seq_len)\n",
    "               type(Variable containing torch.LongTensor)\n",
    "        Return:\n",
    "            pred: shape(batch_size * 2)\n",
    "                  For each sequence in the mini batch, output the probability\n",
    "                  of it belonging to positive sample and negative sample.\n",
    "            feature: shape(batch_size * self.num_filters_total)\n",
    "                     Corresponding to f_t in original paper\n",
    "            score: shape(batch_size, self.num_classes)\n",
    "              \n",
    "        \"\"\"\n",
    "        #1. Embedding Layer\n",
    "        #2. Convolution + maxpool layer for each filter size\n",
    "        #3. Combine all the pooled features into a prediction\n",
    "        #4. Add highway\n",
    "        #5. Add dropout. This is when feature should be extracted\n",
    "        #6. Final unnormalized scores and predictions\n",
    "        emb = self.emb(x).unsqueeze(1)\n",
    "        convs = [F.relu(conv(emb)).squeeze(3) for conv in self.convs] # [batch_size * num_filter * seq_len]\n",
    "        pooled_out = [F.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in convs] # [batch_size * num_filter]\n",
    "        pred = torch.cat(pooled_out, 1) # batch_size * sum(num_filters)\n",
    "        #print(\"Pred size: {}\".format(pred.size()))\n",
    "        highway = self.highway(pred)\n",
    "        #print(\"highway size: {}\".format(highway.size()))\n",
    "        highway = torch.sigmoid(highway)* F.relu(highway) + (1.0 - torch.sigmoid(highway))*pred\n",
    "        features = self.dropout(highway)\n",
    "        score = self.fc(features)\n",
    "        pred = F.log_softmax(score, dim=1) #batch * num_classes\n",
    "        return {\"pred\":pred, \"feature\":features, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(seq_len, num_classes, vocab_size, dis_emb_dim, filter_sizes, num_filters, start_token, goal_out_size, step_size, dropout_prob, l2_reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (emb): Embedding(5259, 64)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(1, 64), stride=(1, 1))\n",
       "    (1): Conv2d(1, 200, kernel_size=(2, 64), stride=(1, 1))\n",
       "    (2): Conv2d(1, 200, kernel_size=(3, 64), stride=(1, 1))\n",
       "    (3): Conv2d(1, 200, kernel_size=(4, 64), stride=(1, 1))\n",
       "    (4): Conv2d(1, 200, kernel_size=(5, 64), stride=(1, 1))\n",
       "    (5): Conv2d(1, 100, kernel_size=(6, 64), stride=(1, 1))\n",
       "    (6): Conv2d(1, 100, kernel_size=(7, 64), stride=(1, 1))\n",
       "    (7): Conv2d(1, 100, kernel_size=(8, 64), stride=(1, 1))\n",
       "    (8): Conv2d(1, 100, kernel_size=(9, 64), stride=(1, 1))\n",
       "    (9): Conv2d(1, 100, kernel_size=(10, 64), stride=(1, 1))\n",
       "    (10): Conv2d(1, 160, kernel_size=(15, 64), stride=(1, 1))\n",
       "    (11): Conv2d(1, 160, kernel_size=(20, 64), stride=(1, 1))\n",
       "  )\n",
       "  (highway): Linear(in_features=1720, out_features=1720, bias=True)\n",
       "  (dropout): Dropout(p=0.8, inplace=False)\n",
       "  (fc): Linear(in_features=1720, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_array: torch.Size([20, 64])\n",
      "new_input: torch.Size([1, 1, 20, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Int but got scalar type Float for argument #3 'mat1' in call to _th_addmm_",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-be2bd42685a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnew_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"new_input: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnew_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv2d_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"new_output: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Int but got scalar type Float for argument #3 'mat1' in call to _th_addmm_"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "conv2d_1 = nn.Conv2d(1, 100, (1, 64))\n",
    "new_array = torch.from_numpy(np.random.randint(100 , size = (20,64)))\n",
    "print(\"new_array: {}\".format(new_array.size()))\n",
    "new_input = new_array.unsqueeze(0).unsqueeze(0)\n",
    "print(\"new_input: {}\".format(new_input.size()))\n",
    "new_output = conv2d_1(torch.IntTensor(new_input))\n",
    "print(\"new_output: {}\".format(new_output.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2: torch.Size([1, 1, 20, 64])\n",
      "output_1: torch.Size([1, 100, 20, 1])\n"
     ]
    }
   ],
   "source": [
    "input_2 = torch.randn(1, 1, 20, 64)\n",
    "output_1 = conv2d_1(input_2)\n",
    "print(\"input_2: {}\".format(input_2.size()))\n",
    "print(\"output_1: {}\".format(output_1.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2: torch.Size([1, 1, 20, 64])\n",
      "output_2: torch.Size([1, 200, 19, 1])\n"
     ]
    }
   ],
   "source": [
    "conv2d_2 = nn.Conv2d(1, 200, kernel_size=(2, 64), stride=(1, 1))\n",
    "output_2 = conv2d_2(input_2)\n",
    "print(\"input_2: {}\".format(input_2.size()))\n",
    "print(\"output_2: {}\".format(output_2.size()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
